{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "# requires pytorch > 0.3.1\n",
    "try:\n",
    "  import torch\n",
    "  import torch.nn as nn\n",
    "  from torch.autograd import Variable\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "\n",
    "# import the code, add path first\n",
    "# for example\n",
    "solver_path = 'I:/AffinityNet'\n",
    "if os.path.exists(solver_path):\n",
    "  sys.path.append(solver_path)\n",
    "\n",
    "try:\n",
    "  from utils.solver import Solver\n",
    "  from affinitynet.graph_attention import *\n",
    "  from affinitynet.test_graph_attention import *\n",
    "except ModuleNotFoundError:\n",
    "  pass\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "signal_dim = 1\n",
    "noisy_dim = 20\n",
    "clu_size = 1000\n",
    "num_clusters = 4\n",
    "hidden_dims = [100]\n",
    "num_iter = 100\n",
    "batch_size = 100\n",
    "lr = 1e-1\n",
    "weight_decay = 1e-4\n",
    "root = '.'\n",
    "save_folder_prefix = '{0}/data/simulation/knn_pooling_toy/seed{1}'.format(root, seed)\n",
    "# if not os.path.exists(save_folder_prefix):\n",
    "#   os.makedirs(save_folder_prefix)\n",
    "save_fig = False\n",
    "figsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array([[0,0], [1,0], [0,1], [1,1]]) * 5\n",
    "assert num_clusters == len(means)\n",
    "means = [m*signal_dim for m in means]\n",
    "sigmas = 1.0*np.ones(len(means))\n",
    "x = []\n",
    "y = []\n",
    "for i, (mean, sigma) in enumerate(zip(means, sigmas)):\n",
    "    x.append(np.random.multivariate_normal(mean, sigma*np.eye(len(mean)), size=clu_size))\n",
    "    y.append(i*np.ones(clu_size))\n",
    "x = np.concatenate(x, axis=0)\n",
    "y = np.concatenate(y, axis=0)\n",
    "\n",
    "title = 'input'\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(x[:,0], x[:,1], c=y)\n",
    "save_folder = save_folder_prefix\n",
    "if save_fig:\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    plt.savefig('{0}/{1}.png'.format(save_folder,title), bbox_inches='tight', dpi=200)\n",
    "else:\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purely unsupervised clustering (same as Graph Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = x.shape[1]\n",
    "x_var = Variable(torch.from_numpy(x).float())\n",
    "y_var = Variable(torch.from_numpy(y).long())\n",
    "num_cls = y_var.data.max().item()+1\n",
    "\n",
    "model = MultiviewAttention(in_dim=in_dim, hidden_dims=[10, 10, 10], k=50, graph=None, \n",
    "                             out_indices=None, \n",
    "                   feature_subset=None, kernel='gaussian', nonlinearity_1=None,\n",
    "                   nonlinearity_2=None, use_previous_graph=True, \n",
    "                             group_index=None, merge=None,\n",
    "                  merge_type='affine', reset_graph_every_forward=False, \n",
    "                             no_feature_transformation=False, rescale=True, merge_dim=2, \n",
    "                          layer_norm=False)\n",
    "\n",
    "features = FeatureExtractor(model.layers, selected_layers=range(len(model.layers)))\n",
    "y_pred = features(x_var)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "  plot_scatter(y_pred[i], title='y_pred[{0}]'.format(i), colors=y, \n",
    "               folder=save_folder, save_fig=save_fig, \n",
    "               size=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the results in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.multivariate_normal([2.5]*noisy_dim*2, 10*np.eye(noisy_dim*2), size=len(y))\n",
    "x = np.concatenate([x[:,:signal_dim],z[:,:noisy_dim],x[:,signal_dim:],z[:,noisy_dim:]],axis=1)\n",
    "in_dim = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classifiers(X_train, X_test, y_train, y_test, names, classifiers, res=None):\n",
    "  def eval_classifiers(X_test, y_test):\n",
    "    acc_test = []\n",
    "    nmi_test = []\n",
    "    f1_score_test = []\n",
    "    confusion_mat_test = []\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = sklearn.metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "        nmi = sklearn.metrics.adjusted_mutual_info_score(labels_true=y_test, labels_pred=y_pred)\n",
    "        confusion_mat = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "        f1_score = sklearn.metrics.f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "        print('{0}: acc={1:.2f}, nmi={2:.2f}, f1={3:.2f}, confusion_mat:\\n{4}'.format(name, acc, nmi, \n",
    "                                                                        f1_score, confusion_mat))\n",
    "        acc_test.append(acc)\n",
    "        nmi_test.append(nmi)\n",
    "        f1_score_test.append(f1_score)\n",
    "        confusion_mat_test.append(confusion_mat)\n",
    "    return acc_test, nmi_test, f1_score_test, confusion_mat_test\n",
    "  \n",
    "  acc_test, nmi_test, f1_score_test, confusion_mat_test = eval_classifiers(X_test, y_test)\n",
    "  acc_train, nmi_train, f1_score_train, confusion_mat_train = eval_classifiers(X_train, y_train)\n",
    "  if res is not None:\n",
    "    acc_test = acc_test + res['test']['acc']\n",
    "    nmi_test = nmi_test + res['test']['nmi']\n",
    "    f1_score_test = f1_score_test + res['test']['f1_score']\n",
    "    confusion_mat_test = confusion_mat_test + res['test']['confusion_mat']\n",
    "    acc_train = acc_train + res['train']['acc']\n",
    "    nmi_train = nmi_train + res['train']['nmi']\n",
    "    f1_score_train = f1_score_train + res['train']['f1_score']\n",
    "    confusion_mat_train = confusion_mat_train + res['train']['confusion_mat']\n",
    "  res = {'train': {'acc': acc_train, 'nmi': nmi_train, 'f1_score': f1_score_train, \n",
    "                  'confusion_mat': confusion_mat_train},\n",
    "        'test': {'acc': acc_test, 'nmi': nmi_test, 'f1_score': f1_score_test, \n",
    "                  'confusion_mat': confusion_mat_test}}\n",
    "  return res\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "names = [\"Neural Net\", \"Decision Tree\", \"AdaBoost\", \"Nearest Neighbors\", \"Linear SVM\", \n",
    "           \"RBF SVM\", \"Random Forest\", \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "      MLPClassifier(alpha=1),\n",
    "      DecisionTreeClassifier(max_depth=5),\n",
    "      AdaBoostClassifier(),\n",
    "      KNeighborsClassifier(3),\n",
    "      SVC(kernel=\"linear\"),\n",
    "      SVC(gamma=2, C=1),\n",
    "      RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "      GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_weight(feature_weight_all, colors, title):\n",
    "  plt.figure(figsize=(figsize, figsize))\n",
    "  plt.scatter(range(len(feature_weight_all)), feature_weight_all, c=colors, s=20)\n",
    "  plt.xlabel('index')\n",
    "  plt.ylabel('weight')\n",
    "  if save_fig:\n",
    "      if not os.path.exists(save_folder):\n",
    "          os.makedirs(save_folder)\n",
    "      plt.savefig('{0}/{1}.png'.format(save_folder,title), bbox_inches='tight', dpi=200)\n",
    "  else:\n",
    "      plt.title(title)\n",
    "      plt.show()\n",
    "  plt.close()\n",
    "\n",
    "def plot_feature_weight_affinitynet(model_layers, title):\n",
    "  print(title)\n",
    "  feature_weight_all = np.ones(in_dim)\n",
    "  for i in range(len(model_layers)):\n",
    "      feature_weight = nn.functional.softmax(model_layers[i].components[0].a, 0).detach().cpu().data.numpy()\n",
    "      print('layer{0}: {2}, {1}'.format(\n",
    "          i, feature_weight[range(0, in_dim, signal_dim+noisy_dim)].tolist(),\n",
    "          feature_weight[range(0, in_dim, signal_dim+noisy_dim)].sum()/feature_weight.sum()))\n",
    "      feature_weight_all *= feature_weight\n",
    "  feature_weight_all /= feature_weight_all.sum()\n",
    "  print('overall: {1}, {0}'.format(\n",
    "          feature_weight_all[range(0, in_dim, signal_dim+noisy_dim)].tolist(),\n",
    "          feature_weight_all[range(0, in_dim, signal_dim+noisy_dim)].sum()))\n",
    "  # put signal feature in the beginning\n",
    "  feature_weight_all = np.concatenate([feature_weight_all[:signal_dim], \n",
    "                  feature_weight_all[signal_dim+noisy_dim:2*signal_dim+noisy_dim],\n",
    "                  feature_weight_all[signal_dim:signal_dim+noisy_dim], \n",
    "                  feature_weight_all[2*signal_dim+noisy_dim:]])\n",
    "  colors = ['r']*2*signal_dim + ['b']*2*noisy_dim\n",
    "  plot_feature_weight(feature_weight_all, colors, title)\n",
    "  \n",
    "def plot_result(loss_train, acc_train, loss_val, acc_val, avg='avg', \n",
    "                title_prefix='training-affinitynet'):\n",
    "  title = '{0}_best_val_acc_{1}={2}'.format(title_prefix, avg, acc_val[avg][-1])\n",
    "  plt.figure(figsize=(figsize, figsize))\n",
    "  plt.subplot(211)\n",
    "  plt_loss_train, = plt.plot(loss_train[avg], 'r--')\n",
    "  plt_loss_val, = plt.plot(loss_val[avg], 'g-')\n",
    "  plt.legend([plt_loss_train, plt_loss_val], ['train', 'validation'], loc=0)\n",
    "  plt.ylabel('loss')\n",
    "  plt.subplot(212)\n",
    "  plt_acc_train, = plt.plot(acc_train[avg], 'r--')\n",
    "  plt_acc_val, = plt.plot(acc_val[avg], 'g-')\n",
    "  plt.legend([plt_acc_train, plt_acc_val], ['train', 'validation'], loc=0)\n",
    "  plt.ylabel('accuracy %')\n",
    "  plt.xlabel('iterations')\n",
    "  if save_fig:\n",
    "      if not os.path.exists(save_folder):\n",
    "          os.makedirs(save_folder)\n",
    "      plt.savefig('{0}/{1}.png'.format(save_folder,title), bbox_inches='tight', dpi=200)\n",
    "  else:\n",
    "      plt.title(title)\n",
    "      plt.show()\n",
    "  plt.close()\n",
    "\n",
    "def plot_feature_weight_linear(model, title):\n",
    "  print(title)\n",
    "  feature_weight = model.layers.linear0.weight\n",
    "  for i in range(1, 1+len(model.layers)//2):\n",
    "    feature_weight = torch.mm(getattr(model.layers, 'linear'+str(i)).weight, feature_weight)\n",
    "  feature_weight = feature_weight.data.abs().mean(0).numpy()\n",
    "  feature_weight_all = feature_weight / feature_weight.sum()\n",
    "  print('overall: {0}, {1}'.format(\n",
    "    feature_weight_all[range(0, in_dim, signal_dim+noisy_dim)].sum(),\n",
    "    feature_weight_all[range(0, in_dim, signal_dim+noisy_dim)].tolist()))\n",
    "\n",
    "  # put signal feature in the beginning\n",
    "  feature_weight_all = np.concatenate([feature_weight_all[:signal_dim], \n",
    "                  feature_weight_all[signal_dim+noisy_dim:2*signal_dim+noisy_dim],\n",
    "                  feature_weight_all[signal_dim:signal_dim+noisy_dim], \n",
    "                  feature_weight_all[2*signal_dim+noisy_dim:]])\n",
    "  colors = ['r']*2*signal_dim + ['b']*2*noisy_dim\n",
    "  plot_feature_weight(feature_weight_all, colors, title)\n",
    "\n",
    "def eval_affinitynet(data, res):\n",
    "  model = MultiviewAttention(in_dim=in_dim, hidden_dims=[in_dim], k=10, graph=None, \n",
    "                             out_indices=None, \n",
    "                   feature_subset=None, kernel='gaussian', nonlinearity_1=None,\n",
    "                   nonlinearity_2=None, use_previous_graph=False, \n",
    "                             group_index=None, merge=None,\n",
    "                  merge_type='affine', reset_graph_every_forward=False, \n",
    "                             no_feature_transformation=True, rescale=True, merge_dim=2)\n",
    "\n",
    "  if x_var.numel() < 10**6:\n",
    "      title = 'raw data PCA'\n",
    "      plot_scatter(x_var, title=title, colors=y, folder=save_folder, save_fig=save_fig, \n",
    "                  size=figsize)\n",
    "\n",
    "      y_pred = model(x_var)\n",
    "      title = 'before training output PCA'\n",
    "      plot_scatter(y_pred, title=title, colors=y, folder=save_folder, save_fig=save_fig, \n",
    "                  size=figsize)\n",
    "\n",
    "  title = 'feature weight distribution: before training'\n",
    "  plot_feature_weight_affinitynet(model.layers, title)\n",
    "\n",
    "  model = nn.Sequential(model, DenseLinear(in_dim, hidden_dims+[num_cls]))\n",
    "\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "  solver = Solver(model, data, optimizer, loss_fn)\n",
    "\n",
    "  loss_train, acc_train, loss_val, acc_val = solver.train_eval(\n",
    "    num_iter=num_iter, batch_size=batch_size,X=None, y=None, X_val=None, y_val=None,\n",
    "    X_test=None, y_test=None, eval_test=False, balanced_sample=True)\n",
    "\n",
    "  plot_result(loss_train, acc_train, loss_val, acc_val, avg='avg')\n",
    "  plot_result(loss_train, acc_train, loss_val, acc_val, avg='batch')\n",
    "\n",
    "  title = 'Feature weights after training'\n",
    "  plot_feature_weight_affinitynet(model[0].layers, title)\n",
    "\n",
    "  acc, nmi, confusion_mat, f1_score = visualize_val(\n",
    "    data['X_train'], data['y_train'], solver, batch_size=batch_size, \n",
    "    title='affinitynet X_train', topk=1, save_fig=save_fig, save_folder=save_folder)\n",
    "  res[train_portion]['train']['acc'].append(acc)\n",
    "  res[train_portion]['train']['nmi'].append(nmi)\n",
    "  res[train_portion]['train']['f1_score'].append(f1_score)\n",
    "  res[train_portion]['train']['confusion_mat'].append(confusion_mat)\n",
    "\n",
    "  acc, nmi, confusion_mat, f1_score = visualize_val(\n",
    "    data['X_val'], data['y_val'], solver, batch_size=batch_size, title='affinitynet X_val', topk=1,\n",
    "    save_fig=save_fig, save_folder=save_folder)\n",
    "  res[train_portion]['test']['acc'].append(acc)\n",
    "  res[train_portion]['test']['nmi'].append(nmi)\n",
    "  res[train_portion]['test']['f1_score'].append(f1_score)\n",
    "  res[train_portion]['test']['confusion_mat'].append(confusion_mat)\n",
    "\n",
    "  cnt = 0\n",
    "  for n, p in model.named_parameters():\n",
    "      print(n, p.numel())\n",
    "      cnt += p.numel()\n",
    "  print('total param:{0}'.format(cnt))\n",
    "\n",
    "  model = DenseLinear(in_dim, hidden_dims+[num_cls])\n",
    "\n",
    "  cnt = 0\n",
    "  for n, p in model.named_parameters():\n",
    "      print(n, p.numel())\n",
    "      cnt += p.numel()\n",
    "  print('total param:{0}'.format(cnt))    \n",
    "\n",
    "  title = 'Feature weights before training Linear'\n",
    "  plot_feature_weight_linear(model, title)\n",
    "\n",
    "  # set a smaller learning rate for DenseLinear\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=weight_decay)\n",
    "\n",
    "  solver = Solver(model, data, optimizer, loss_fn)\n",
    "\n",
    "  loss_train, acc_train, loss_val, acc_val = solver.train_eval(\n",
    "    num_iter=num_iter, batch_size=batch_size,X=None, y=None, X_val=None, y_val=None,\n",
    "    X_test=None, y_test=None, eval_test=False, balanced_sample=True)\n",
    "\n",
    "  plot_result(loss_train, acc_train, loss_val, acc_val, avg='avg', title_prefix = 'training-linear')\n",
    "  plot_result(loss_train, acc_train, loss_val, acc_val, avg='batch', title_prefix = 'training-linear')\n",
    "\n",
    "  title = 'Feature weights after training Linear'\n",
    "  plot_feature_weight_linear(model, title)\n",
    "\n",
    "  acc, nmi, confusion_mat, f1_score = visualize_val(\n",
    "    data['X_train'], data['y_train'], solver, batch_size=batch_size, \n",
    "    title='linear X_train', topk=1, save_fig=save_fig, save_folder=save_folder)\n",
    "  res[train_portion]['train']['acc'].append(acc)\n",
    "  res[train_portion]['train']['nmi'].append(nmi)\n",
    "  res[train_portion]['train']['f1_score'].append(f1_score)\n",
    "  res[train_portion]['train']['confusion_mat'].append(confusion_mat)\n",
    "\n",
    "  acc, nmi, confusion_mat, f1_score = visualize_val(\n",
    "    data['X_val'], data['y_val'], solver, batch_size=batch_size, title='linear X_val', topk=1,\n",
    "    save_fig=save_fig, save_folder=save_folder)\n",
    "  res[train_portion]['test']['acc'].append(acc)\n",
    "  res[train_portion]['test']['nmi'].append(nmi)\n",
    "  res[train_portion]['test']['f1_score'].append(f1_score)\n",
    "  res[train_portion]['test']['confusion_mat'].append(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = Variable(torch.from_numpy(x).float())\n",
    "y_var = Variable(torch.from_numpy(y).long())\n",
    "num_cls = y_var.data.max().item() + 1\n",
    "\n",
    "train_portions = [0.005, 0.01, 0.1, 0.2, 0.5, 0.8]\n",
    "res = {}\n",
    "\n",
    "for train_portion in train_portions:\n",
    "  proportions = [train_portion]*num_cls\n",
    "  x_train, y_train, x_test, y_test, train_idx, test_idx = split_data(\n",
    "      x_var, y_var, proportions=proportions, seed=seed)\n",
    "  print('train size: {0}, test size: {1}'.format(y_train.size(0), y_test.size(0)))\n",
    "\n",
    "  data = {'X_train':x_train.data, 'y_train':y_train.data, 'X_val':x_test.data, 'y_val':y_test.data, \n",
    "         'X_test':x_test.data, 'y_test':y_test.data}\n",
    "  save_folder = '{0}/train_portion-{1}/'.format(save_folder_prefix, train_portion)\n",
    "  \n",
    "  res[train_portion] = compare_classifiers(x_train.data.numpy(), x_test.data.numpy(), \n",
    "                                          y_train.data.numpy(), y_test.data.numpy(), \n",
    "                                           names, classifiers)\n",
    "  eval_affinitynet(data, res)\n",
    "\n",
    "if not os.path.exists(save_folder_prefix):\n",
    "  os.mkdir(save_folder_prefix)\n",
    "with open('{0}/res.pkl'.format(save_folder_prefix), 'wb') as f:\n",
    "  pickle.dump(res, f)\n",
    "  \n",
    "# with open(save_folder_prefix+'res.pkl', 'rb') as f:\n",
    "#   data = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
